{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_path = str(input('Type in the path of folder \"fpilarova_masters-main\" (ex. C:\\\\\\\\Users\\\\\\\\frant\\\\\\\\Desktop\\\\\\\\fpilarova_masters-main):\\n'))\n",
    "\n",
    "main_path = win_path.replace('\\\\\\\\', '\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import httplib2 as http\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import fastaparser\n",
    "from collections import Counter\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from urlparse import urlparse\n",
    "except ImportError:\n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ResourceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1 Get a list of stress molecule symbols\n",
    "**Description of the script:**\n",
    "1. List of gene symbols is downloaded; for every pathway requested (input: Reactome ID)\n",
    "2. The symbols are checked to be HGNC-approved\n",
    "    - if not -> printed (EDIT - ask HGNC for HGNC-approved name of that gene)\n",
    "3. Checked symbols are added to the final list (stress_molecules_list = containing stress molecules of all requested Reactome IDs)\n",
    "5. Table gene_in_multiple_paths_check is created; with information about in which Reactome pathways the genes are involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stress_molecules_list = []\n",
    "#stress_molecules_list = ['AAAS', 'HSF1'] #TEST\n",
    "# final list of all stress molecules; to be saved as stress_molecules.csv\n",
    "      \n",
    "reactome_ids_symbols_dictionary = {}\n",
    "# dictionary of Reactome ids and their HGNC-approved gene symbols\n",
    "# {Reactome_ID_1: [gene_1, gene_2], ...}\n",
    "\n",
    "gene_in_multiple_paths_check = {}\n",
    "# dictionary of genes and Reactome IDs in which the genes are included\n",
    "# {gene_1: [Reactome_ID_1, Reactome_ID_2], ...} \n",
    "\n",
    "HGNC_not = []\n",
    "# list of gene symbols that are not HGNC-approved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Ask user for Reactome path IDs\n",
    "**Input:**\n",
    "- reactome_ids = list of Reactome IDs\n",
    "- reactome_names (optional)\n",
    "\n",
    "\n",
    "**Testing input:**\n",
    "\n",
    "- R-HSA-3371556 R-HSA-9612973 R-HSA-9711097 R-HSA-381119\n",
    "- hsr autophagy starvation upr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ask for input\n",
    "\n",
    "reactome_ids_input = str(input(' Enter Reactome path IDs (with spaces as separators):')) # ask for IDs\n",
    "reactome_ids = reactome_ids_input.split(' ')\n",
    "pathway_names_input = str(input('\\n Do you want to name them? \\n Yes - enter the names (with spaces as separators) \\n No - press enter \\n')) #ask for names if needed\n",
    "pathway_names = pathway_names_input.split(' ')\n",
    "\n",
    "while (len(reactome_ids) != len(pathway_names)) and (pathway_names[0] != ''): # check if there is the same number of names and ids\n",
    "    print(' Error: there is different number of path IDs and path names.')\n",
    "    reactome_ids_input = str(input(' Enter Reactome path IDs (with spaces as separators): '))\n",
    "    reactome_ids = reactome_ids_input.split(' ')\n",
    "    pathway_names_input = str(input('Do you want to name them? \\n Yes - enter the names (with spaces as separators) \\n No - press enter \\n'))\n",
    "    pathway_names = pathway_names_input.split(' ')\n",
    "\n",
    "\n",
    "# inform about requested IDs\n",
    "\n",
    "print('\\n List of Reactome IDs saved to be examined later:') \n",
    "for i in range(len(reactome_ids)):                                           \n",
    "    if pathway_names[0] != '':\n",
    "        print(reactome_ids[i], ' (', pathway_names[i], ')', sep='')\n",
    "    else:\n",
    "        print(reactome_ids[i])\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Download the symbols from Reactome and check if they are HGNC-approved\n",
    "**Description of the script:**\n",
    "1. Gene symbols from Reactome are downloaded (using Reactome IDs requested earlier)\n",
    "2. The symbols are checked to be HGNC-approved\n",
    "3. List stress_molecules_list is created; containing HGNC-approved symbols, each only once\n",
    "4. Dictionary 'gene_in_multiple_paths_check' is generated to identify genes that are involved in multiple Reactome pathways.\n",
    "\n",
    "Results:\n",
    "1. stress_molecules_list\n",
    "    - stress_molecules.csv\n",
    "2. gene_in_multiple_paths_check \n",
    "    - gene_in_multiple_paths_check.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k in range(len(reactome_ids)): # for every Reactome ID requested:\n",
    "    \n",
    "    if pathway_names[0] != '':    \n",
    "        print('Gene symbols of pathway: {0} (ID: {1}) are being downloaded and checked...'.format(pathway_names[k], reactome_ids[k]))\n",
    "    else: \n",
    "        print('Gene symbols of pathway with ID: {} are being downloaded and checked...'.format(reactome_ids[k]))\n",
    "    \n",
    "    \n",
    "    reactome_id = reactome_ids[k]\n",
    "    \n",
    "    working_symbols_list = []        # list of gene symbols of current Reactome ID to be HGNC-checked\n",
    "    \n",
    "    HGNC_approved_symbols_list = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    # download a list of molecules using Reactome API \n",
    "    \n",
    "    headers = {'Accept': 'application/json'}\n",
    "\n",
    "    uri = 'https://reactome.org/ContentService/data/participants'\n",
    "    path = '/{}'.format(reactome_id)\n",
    "\n",
    "    target = urlparse(uri+path)\n",
    "    method = 'GET'\n",
    "    body = ''\n",
    "\n",
    "    h = http.Http()\n",
    "\n",
    "    response, content = h.request(\n",
    "        target.geturl(),\n",
    "        method,\n",
    "        body,\n",
    "        headers)\n",
    "\n",
    "\n",
    "    if response['status'] == '200':    # assume that content is a json reply\n",
    "        data = json.loads(content)     # parse content with the json module \n",
    "\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            for j in range(len(data[i]['refEntities'])):\n",
    "                if 'UniProt' in data[i]['refEntities'][j]['displayName']:         # choose only UniProt outcomes; i.e. gene symbols\n",
    "                    symbol = data[i]['refEntities'][j]['displayName'].split()[1]\n",
    "                    if symbol not in working_symbols_list:                        # check that every symbol is only once\n",
    "                        working_symbols_list.append(symbol)\n",
    "\n",
    "    else:\n",
    "        print( 'Error detected: ' + response['status'])\n",
    "           \n",
    "    \n",
    "    \n",
    "    # with using HGNC API find out if symbols are HGNC-approved\n",
    "\n",
    "    if len(working_symbols_list) != 0:                 # if list is not empty\n",
    "        for symbol in working_symbols_list:            # check every symbol in list\n",
    "            \n",
    "            # set the url\n",
    "            headers = {'Accept': 'application/json'}\n",
    "\n",
    "            uri = 'https://rest.genenames.org'\n",
    "            path = '/search/symbol/{}'.format(symbol)\n",
    "\n",
    "            target = urlparse(uri+path)\n",
    "            method = 'GET'\n",
    "            body = ''\n",
    "\n",
    "            h = http.Http()\n",
    "\n",
    "            response, content = h.request(\n",
    "                target.geturl(),\n",
    "                method,\n",
    "                body,\n",
    "                headers)\n",
    "\n",
    "            if response['status'] == '200':            # assume that content is a json reply\n",
    "                data = json.loads(content)             # parse content with the json module \n",
    "                check = data['response']['numFound']   # check can be 0 (not HGNC-approved) or 1 (approved)\n",
    "\n",
    "                if (check == 0) and (symbol not in HGNC_not):\n",
    "                    HGNC_not.append(symbol)\n",
    "                elif (check == 1) and (symbol not in HGNC_approved_symbols_list):\n",
    "                    HGNC_approved_symbols_list.append(symbol)\n",
    "\n",
    "            else:\n",
    "                print( 'Error detected: ' + response['status'])\n",
    "        \n",
    "        reactome_ids_symbols_dictionary[reactome_id] = HGNC_approved_symbols_list      # 'reactome_id_1: [gene_1, gene2, ...]' is added to dictionary\n",
    "        \n",
    "\n",
    "    else: \n",
    "        print('Error: there is no data for {}.'.format(reactome_id))\n",
    "    \n",
    "    for gene in HGNC_approved_symbols_list:\n",
    "        if gene not in stress_molecules_list: \n",
    "            stress_molecules_list.append(gene)  # HGNC-approved symbols added to list of stress molecules (--> stress_molecules.csv)\n",
    "        \n",
    "        if gene not in gene_in_multiple_paths_check.keys():\n",
    "            gene_in_multiple_paths_check.update({gene: [reactome_id]})\n",
    "        else:\n",
    "            gene_in_multiple_paths_check[gene].append(reactome_id)\n",
    "        \n",
    "\n",
    "\n",
    "# print symbols that are not HGNC-approved\n",
    "\n",
    "if len(HGNC_not) != 0:    \n",
    "    print('\\n Symbols not HGNC-approved:', sep = ' ')\n",
    "    for gene in HGNC_not:\n",
    "        print(gene, sep = ' ')\n",
    "\n",
    "        \n",
    "\n",
    "df_stress_molecules = pd.DataFrame(stress_molecules_list, columns = ['symbol'])\n",
    "    \n",
    "multiple_paths_df = pd.DataFrame.from_dict(gene_in_multiple_paths_check, orient = 'index')\n",
    "\n",
    "\n",
    "print('\\n Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: List of stress molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_stress_molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results: Multiple paths check\n",
    "To identify genes that are involved in multiple Reactome pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_paths_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 Get orthologs for every \"stress molecule\"; from NCBI\n",
    "**Description of the script:** \n",
    "1. Download and save FASTA files using NCBI Datasets\n",
    "    - FASTA file (orthologs) for every stress molecule using NCBI Datasets (datasets.exe) is downloaded and saved\n",
    "2. Parse FASTA files\n",
    "    - FASTA files are parsed and saved to: \n",
    "        - orthologs_list with all information from FASTA file saved\n",
    "        - orthologs_count for analysis of count of sequences per gene id\n",
    "        - genes_organisms_dictionary for genes-organisms check\n",
    "        - all_orthologs_refseqs_sorted for selection of one sequence per gene id\n",
    "3. Genes-organisms check\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download and save FASTA files using NCBI Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('FASTA files for every stress molecule containing data with orthologous sequences are being downloaded and saved... \\n') \n",
    "\n",
    "for stress_molecule in stress_molecules_list:\n",
    "    os.system('datasets download ortholog symbol {1} --taxon-filter mammals --exclude-rna --exclude-gene --filename {0}\\\\NCBI_Datasets_download\\\\{1}.zip'.format(win_path, stress_molecule))\n",
    "    os.system('cd {0}\\\\NCBI_Datasets_download\\\\ & tar -xf {0}\\\\NCBI_Datasets_download\\\\{1}.zip'.format(win_path, stress_molecule))\n",
    "    os.system('move {0}\\\\NCBI_Datasets_download\\\\ncbi_dataset\\\\data\\\\protein.faa {0}\\\\NCBI_Datasets_download'.format(win_path))\n",
    "    os.system('ren {0}\\\\NCBI_Datasets_download\\\\protein.faa {1}.faa'.format(stress_molecule))\n",
    "    os.system('del {0}\\\\NCBI_Datasets_download\\\\{1}.zip'.format(win_path, stress_molecule))\n",
    "os.system('del {0}\\\\NCBI_Datasets_download\\\\README.md'.format(win_path))\n",
    "os.system('rmdir /s /q {0}\\\\NCBI_Datasets_download\\\\ncbi_dataset'.format(win_path))\n",
    "\n",
    "\n",
    "files = os.listdir(r'{0}\\NCBI_Datasets_download'.format(main_path))\n",
    "files.remove('.ipynb_checkpoints')\n",
    "\n",
    "\n",
    "for stress_molecule in stress_molecules_list:\n",
    "    if str(stress_molecule) + '.faa' not in files:\n",
    "        print('Error: a file for', stress_molecule, 'was not downloaded. \\n')\n",
    "        stress_molecules_list.remove(stress_molecule)\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parse FASTA files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARIABLES\n",
    "gene_ids = [] \n",
    "# gene ids of all orthologs (of all stress molecules together)\n",
    "\n",
    "orthologs_list = [] \n",
    "# list of all orthologous sequences and information about them\n",
    "# [{human_gene_name: X, gene id: X, gene name: X, organism name; X, accession_number (that is refseq number): X, protein sequence: X}, {...}]\n",
    "# -> orthologs.csv\n",
    "\n",
    "\n",
    "# TO SEE HOW MANY REFERENCE SEQUENCES THERE ARE FOR ONE GENE ID\n",
    "orthologs_count_list = []\n",
    "# list of genes and count of its sequences (refseq) downloaded from NCBI \n",
    "# [{human_gene_name: x, gene_id: x, seq_count = x, most_repres_seq_count = x, unique_seq_count = x}, {...}, ...]\n",
    "\n",
    "already_been_there = []\n",
    "# working list\n",
    "\n",
    "\n",
    "# FOR GENES-ORGANISMS CHECK\n",
    "genes_organisms_dictionary = {}\n",
    "\n",
    "\n",
    "\n",
    "# FOR SELECTION OF ONE SEQUENCE PER GENE ID\n",
    "all_orthologs_refseqs_sorted = {}\n",
    "# {gene_id1: \n",
    "#     {RefSeq1: \n",
    "#          {protein_sequence: X, human_gene_name: X, gene_name: X, organism: X}, \n",
    "#      RefSeq2: {...}\n",
    "#     }, \n",
    "#  gene_id2: \n",
    "#      {RefSeq3: {}\n",
    "#     }, \n",
    "#  ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent_count(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][1]\n",
    "\n",
    "def most_frequent_name(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Script: Parse FASTA files and save the information into lists and dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse all FASTA files downloaded \n",
    "# every file is named as the gene which orthologs seqs it contains of\n",
    "\n",
    "files = os.listdir(r'{0}\\NCBI_Datasets_download'.format(main_path))\n",
    "files.remove('.ipynb_checkpoints')\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    gene_name = file.replace('.faa', '')\n",
    "\n",
    "    orthologs_count_dictionary = {}   # working dictionary; will be used for \"seqs count check\" \n",
    "                                      # {gene_id1: [seq1, seq2, seq3], gene_id2: [seq1, seq2], ...}\n",
    "    \n",
    "    organism_gene_id_dict = {}        # working dictionary; will be used for genes-organisms check\n",
    "        \n",
    "    with open(r'{0}\\NCBI_Datasets_download\\{1}'.format(main_path, file)) as fasta_file:\n",
    "        parser = fastaparser.Reader(fasta_file)\n",
    "        \n",
    "        for seq in parser: # for every record (ortholog) of FASTA file        \n",
    "            \n",
    "            # split the FASTA record \n",
    "            working_list = seq.description.split(\" [\")     \n",
    "            gene_id = (re.findall('\\\\d+', working_list[2])[0])\n",
    "            gene_ids.append(gene_id)\n",
    "\n",
    "\n",
    "            \n",
    "            ### for orthologs.csv ###\n",
    "            # add seq (ortholog) atributes to orthologs_list\n",
    "            \n",
    "            ortholog_dictionary = {}   # {human_gene_name: X, gene id: X, gene name: X, organism name; X, accession number: X, protein sequence: X}\n",
    "            \n",
    "            ortholog_dictionary['human_gene_name'] = gene_name                              # human gene name added\n",
    "            ortholog_dictionary['gene_name'] = working_list[0]                              # gene name added\n",
    "            organism_name = working_list[1][9:].replace(\"]\", \"\")\n",
    "            organism_name = organism_name.replace(\" \", \"_\")\n",
    "            ortholog_dictionary['organism'] = organism_name                                 # organism name added\n",
    "            ortholog_dictionary['gene_id'] = gene_id                                        # gene ID added\n",
    "            ortholog_dictionary['accession_number'] = seq.id                                # accession number added \n",
    "            ortholog_dictionary['protein_sequence'] = seq.sequence_as_string()              # protein sequence with its accession number added\n",
    "\n",
    "            orthologs_list.append(ortholog_dictionary)\n",
    "            # orthologs_list = [{human_gene_name: X, gene id: X, gene name: X, organism name; X, accession number: X, protein sequence: X}, {...}]\n",
    "            \n",
    "            \n",
    "\n",
    "            ### for orthologs_count.csv and final_orthologs_seqs.csv ###     \n",
    "            # add sequence to orthologs_count_dictionary {gene_id1: [seq1, seq2, seq3], gene_id2: [seq1, seq2], ...}\n",
    "            # add RefSeq number and sequence to all_orthologs_refseqs_sorted dictionary {gene_id1: {RefSeq1: seq1, RefSeq2: seq2, ...}, gene_id2: {}, ...}\n",
    "            \n",
    "            if gene_id not in already_been_there: \n",
    "                first_sequence = seq.sequence_as_string()\n",
    "                orthologs_count_dictionary[gene_id] = [first_sequence]\n",
    "                all_orthologs_refseqs_sorted[gene_id] = {}\n",
    "                all_orthologs_refseqs_sorted[gene_id].update({seq.id: {'protein_sequence': seq.sequence_as_string(), 'human_gene_name': gene_name, 'gene_name': working_list[0], 'organism': working_list[1][9:].replace(\"]\", \"\")}})\n",
    "                \n",
    "            else:\n",
    "                another_sequence = seq.sequence_as_string()\n",
    "                orthologs_count_dictionary[gene_id].append(another_sequence)\n",
    "                all_orthologs_refseqs_sorted[gene_id].update({seq.id: {'protein_sequence': seq.sequence_as_string(), 'human_gene_name': gene_name, 'gene_name': working_list[0], 'organism': working_list[1][9:].replace(\"]\", \"\")}})\n",
    "\n",
    "            already_been_there.append(gene_id)\n",
    "            \n",
    "            \n",
    "            \n",
    "            ### for genes_organisms_check.csv ###\n",
    "            organism_gene_id_dict[organism_name] = gene_id      \n",
    "\n",
    "            \n",
    "        genes_organisms_dictionary.update({gene_name : organism_gene_id_dict})\n",
    "        # {gene_name1: {organism1: gene_id1, organism2: gene_id2, ...}, gene_name2: {}, ...}\n",
    "            \n",
    "            \n",
    "    \n",
    "    ### for orthologs_count.csv ###     \n",
    "    # create dictionary with gene ids and their protein sequence counts (and the most represented sequence)\n",
    "    \n",
    "    for key in orthologs_count_dictionary.keys():\n",
    "        ortholog = {}\n",
    "        ortholog['human_gene_name'] = file.strip('.faa')\n",
    "        ortholog['gene_id'] = str(key)\n",
    "        ortholog['seq_count'] = len(orthologs_count_dictionary[key])\n",
    "        ortholog['most_repres_seq_count'] = most_frequent_count(orthologs_count_dictionary[key])\n",
    "        \n",
    "        counter_keys = Counter(orthologs_count_dictionary[key])\n",
    "        ortholog['unique_seq_count'] = len(counter_keys.keys())\n",
    "        \n",
    "        orthologs_count_list.append(ortholog)\n",
    "        # orthologs_count_list = [{human_gene_name: 'xxx.faa', gene_id: x, seq_count = x, most_repres_seq_count = x, unique_seq_count = x}, {...}, ...]\n",
    "\n",
    "\n",
    "df_orthologs_list = pd.DataFrame.from_dict(orthologs_list)\n",
    "df_ortholog_count_list = pd.DataFrame.from_dict(orthologs_count_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results: List of all orthologs downloaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_orthologs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results: Count of reference sequences of every orthologous gene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ortholog_count_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Genes-organisms check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create DataFrame from genes_organisms_dictionary\n",
    "\n",
    "df_genes_organisms = pd.DataFrame(list(genes_organisms_dictionary.values()), index=list(genes_organisms_dictionary.keys()))\n",
    "\n",
    "# variables\n",
    "\n",
    "genes_count = len(genes_organisms_dictionary.keys())\n",
    "organisms_count = 0\n",
    "count_organisms_seq_ratio = {}\n",
    "count_genes_seq_ratio = {}\n",
    "\n",
    "# for which organisms there is enough data? \n",
    "# i.e. ratio of nonexisting vs existing ortholog seqs for every organism\n",
    "for column in df_genes_organisms:\n",
    "    organisms_count += 1\n",
    "    count_organisms_seq_ratio.update({column: df_genes_organisms[column].isnull().sum()/genes_count})\n",
    "\n",
    "# for which genes there is enough data? \n",
    "# i.e. ratio of nonexisting vs existing seqs for every gene\n",
    "for key in genes_organisms_dictionary.keys():\n",
    "    nan_count = df_genes_organisms.loc[[key]].isna().sum().sum()\n",
    "    count_genes_seq_ratio.update({key: nan_count/organisms_count})\n",
    "\n",
    "\n",
    "\n",
    "# pop an organism or a gene from the DataFrame if there is not enough data (seqs) for them \n",
    "\n",
    "organisms_not_enough = []\n",
    "genes_not_enough = []\n",
    "gene_ids_to_pop = [] # list of gene ids to pop from all_orthologs_refseq_sorted (aka list for future analysis)\n",
    "\n",
    "for key in count_organisms_seq_ratio.keys():\n",
    "    if count_organisms_seq_ratio[key] > 0.2:\n",
    "        organisms_not_enough.append(key)\n",
    "        \n",
    "\n",
    "# Remove the organism with too litle data from the analysis\n",
    "for organism in organisms_not_enough:\n",
    "    gene_ids_to_pop += df_genes_organisms[organism].to_list()\n",
    "    df_genes_organisms.pop(organism)\n",
    "    \n",
    "    \n",
    "\n",
    "for key in count_genes_seq_ratio.keys():\n",
    "    if count_genes_seq_ratio[key] > 0.2:\n",
    "        genes_not_enough.append(key)\n",
    "        \n",
    "        \n",
    "# Remove the gene with too litle data from the analysis\n",
    "for gene in genes_not_enough:\n",
    "    gene_ids_to_pop += df_genes_organisms.loc[gene].tolist()\n",
    "    df_genes_organisms.drop(gene, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# print genes and organisms which enough data do not exist for\n",
    "\n",
    "if len(genes_not_enough) != 0:\n",
    "    print('There is not enough data for genes:')\n",
    "    for gene in genes_not_enough:\n",
    "        print(gene)\n",
    "\n",
    "if len(organisms_not_enough) != 0:\n",
    "    print('There is not enough data for organisms:')\n",
    "    for organism in organisms_not_enough:\n",
    "        print(organism)\n",
    "        \n",
    "print('\\n They are not included in future analysis.')\n",
    "\n",
    "\n",
    "\n",
    "# remove organisms and genes with not enough data from all_orthologs_refseqs_sorted\n",
    "gene_ids_to_pop = [b for b in gene_ids_to_pop if isinstance(b, str)] # remove all nan\n",
    "\n",
    "\n",
    "for geneid in gene_ids_to_pop:\n",
    "    del all_orthologs_refseqs_sorted[geneid]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results: Final table of genes, organism and corresponding gene ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_genes_organisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3 Animal Traits & AnAge databases; calculating longevity quotient\n",
    "\n",
    "**Description of script:** Edits data from Animal Traits dataset and saves name of an organism and its body mass to table 'df_animaltraits'. Merges AnAge data and Animal Traits data (table 'df_anage_animaltraits'); and calculate longevity quotient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Script: Load Animal Traits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_animaltraits = pd.read_csv(r'{0}\\AnimalTraits_dataset\\AnimalTraits.csv'.format(main_path), sep=';')\n",
    "\n",
    "animaltraits_bodymass = {}\n",
    "\n",
    "for index, rows in df_animaltraits.iterrows():\n",
    "        name = str(rows.species)\n",
    "        if 'e_' in str(rows.body_mass): \n",
    "            main_num = str(rows.body_mass).split('e_0')\n",
    "            body_mass = float(main_num[0]) / (10 ** float(main_num[1])) * 1000 \n",
    "            df_animaltraits.at[index,'body_mass'] = body_mass\n",
    "            \n",
    "        else: \n",
    "            body_mass = round(float(rows.body_mass) * 1000, 2)\n",
    "            df_animaltraits.at[index,'body_mass'] = body_mass\n",
    "        animaltraits_bodymass.update({name: body_mass})\n",
    "        \n",
    "df_animaltraits = df_animaltraits.iloc[:, [5, 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Results: List of organisms and their body mass (in g) from Animal Traits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_animaltraits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Fill in missing body masses in AnAge with data from Animal Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort(sub_li):\n",
    "    return(sorted(sub_li, key = lambda x: x[1]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_anage = pd.read_csv(r'{0}\\AnAge_dataset\\anage_data.csv'.format(main_path), sep=';')\n",
    "organisms_downloaded = df_genes_organisms.columns.values.tolist()\n",
    "  \n",
    "for index, rows in df_anage.iterrows():\n",
    "        name = str(rows.Genus) + '_' + str(rows.Species)\n",
    "        if math.isnan(rows.Body_mass):\n",
    "            if name in animaltraits_bodymass.keys():\n",
    "                df_anage.at[index,'Body_mass'] = animaltraits_bodymass[name]\n",
    "                \n",
    "df_anage_animaltraits = df_anage.iloc[:, [6,7,20,28]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results: AnAge and Animal Traits merged; table containing max. longevity and body mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_anage_animaltraits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script: Calculate longevity quotient and choose low and top decile (aka short and long-living species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "organisms_in_organisms_lq_list =[]\n",
    "organisms_lq_list_all = []\n",
    "organisms_lq_list_final = []\n",
    "\n",
    "# Go through the AnAge + Animal Traits table and calculate longevity quotient for each organism\n",
    "\n",
    "for index, rows in df_anage_animaltraits.iterrows():\n",
    "        name = str(rows.Genus) + '_' + str(rows.Species)\n",
    "        if not math.isnan(rows.Body_mass) and not math.isnan(rows.Maximum_longevity):\n",
    "           \n",
    "            # maximum longevity\n",
    "            ml = float(rows.Maximum_longevity)\n",
    "            \n",
    "            # body mass\n",
    "            bm = float(rows.Body_mass)\n",
    "\n",
    "            # longevity quotient\n",
    "            lq = round(ml/(6.32*(bm**0.139)), 2)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # All organisms from AnAge and Animal Traits datasets that data on body mass and lifespan exist\n",
    "            \n",
    "            organisms_lq_list_all.append({'organism':name, 'maximum_lifespan':ml, 'body_mass':bm, 'longevity_quotient':lq})\n",
    "            \n",
    "            \n",
    "            \n",
    "            # Overlap between list of organisms, that we have data for, and list of organisms with known bodymasses and lifespans\n",
    "            \n",
    "            if name in organisms_downloaded: \n",
    "                organisms_lq_list_final.append({'organism':name, 'maximum_lifespan':ml, 'body_mass':bm, 'longevity_quotient':lq})\n",
    "        \n",
    "        \n",
    "# FINAL table of all organisms that data for orthologs and longevity quotient are available  \n",
    "            \n",
    "df_organisms_lq = pd.DataFrame.from_dict(organisms_lq_list_final)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate low and top decile of longevity quotients and save them as short and long-living organisms\n",
    "\n",
    "df_organisms_lq['decile_rank'] = pd.qcut(df_organisms_lq['longevity_quotient'], 10, labels = False)\n",
    "\n",
    "df_short_living = df_organisms_lq.loc[df_organisms_lq['decile_rank'].isin([0])]\n",
    "short_living_list = df_short_living['organism'].to_list()\n",
    "\n",
    "df_long_living = df_organisms_lq.loc[df_organisms_lq['decile_rank'].isin([9])]\n",
    "long_living_list = df_long_living['organism'].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: List of organisms sorted by decile rank\n",
    "Low decile - short-living organisms\n",
    "\n",
    "Top decile - long-living organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_organisms_lq.sort_values('decile_rank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: List of short-living organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_living"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: List of long-living organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_living"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script: Create dictionaries to choose one seq per geneid for selected long and short-living organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for long-living organisms, all orthologous sequences sorted by geneid and refseq\n",
    "long_orthologs_refseqs_sorted = {} \n",
    "\n",
    "geneids_long = []\n",
    "\n",
    "for organism in long_living_list: \n",
    "    geneids_long += df_genes_organisms[organism].to_list()\n",
    "\n",
    "geneids_long = [b for b in geneids_long if isinstance(b, str)] # remove all nan\n",
    "\n",
    "for geneid in geneids_long:\n",
    "     long_orthologs_refseqs_sorted.update({geneid:all_orthologs_refseqs_sorted[geneid]})\n",
    "    \n",
    "\n",
    "# for short-living organisms, all orthologous sequences sorted by geneid and refseq\n",
    "short_orthologs_refseqs_sorted = {}\n",
    "\n",
    "geneids_short = []\n",
    "\n",
    "for organism in short_living_list:\n",
    "    geneids_short += df_genes_organisms[organism].to_list()\n",
    "\n",
    "geneids_short = [b for b in geneids_short if isinstance(b, str)] # remove all nan\n",
    "\n",
    "for geneid in geneids_short:\n",
    "    short_orthologs_refseqs_sorted.update({geneid:all_orthologs_refseqs_sorted[geneid]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 SHORT-living; Select reference sequences \n",
    "**Description of script:** It chooses which protein sequence will be used as a reference sequence.\n",
    "\n",
    "Sequence is chosen as a reference if there are keywords 'RefSeq Select' in GenPept file of the protein - script asks NCBI API for GenPept file and check it. Else the longest sequence from all protein sequences of that gene is chosen.\n",
    "\n",
    "seq_selection: \n",
    "  1. 'only_one_seq'; there was only one reference sequence in NCBI dtb\n",
    "  2. 'RefSeq_Select'; RefSeq Select in keywords of GenPept file\n",
    "  3. 'longest_seq'; the longest protein sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_selected_orthologs_list = [] \n",
    "# = list made of the 'orthologs_list' but containing only one seq per gene id\n",
    "# + information if it was chosen with RefSeq Select keyword or it is the longest sequence\n",
    "# [{human_gene_name: X, gene id: X, gene name: X, organism name; X, accession number: X, protein sequence: X, seq_selection: X}, {...}]\n",
    "\n",
    "\n",
    "# testing dictionary \n",
    "# short_orthologs_refseqs_sorted = {'gene_id1': {'NP_001104745': {'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}, 'XP_023505037.1': {'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}}, 'gene_id2': {'XP_023505041.1' :{'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, SIZE=10000):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Parse dictionary short_orthologs_refseqs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all refseqs from dictionary short_orthologs_refseqs_sorted\n",
    "\n",
    "all_refseqs_list = [] \n",
    "gene_ids_list = []\n",
    "\n",
    "for key in list(short_orthologs_refseqs_sorted.keys()):\n",
    "    gene_ids_list.append(key)\n",
    "    for jey in list(short_orthologs_refseqs_sorted[key].keys()): \n",
    "        all_refseqs_list.append(jey)\n",
    "        \n",
    "print('Count of all gene ids:', len(gene_ids_list))\n",
    "print('Count of all refseqs:', len(all_refseqs_list), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# split the dictionary by 50 \n",
    "splitted_short_orthologs_refseqs_sorted = []\n",
    "\n",
    "\n",
    "for item in chunks({i:short_orthologs_refseqs_sorted[i] for i in short_orthologs_refseqs_sorted}, 10):\n",
    "    splitted_short_orthologs_refseqs_sorted.append(item)\n",
    "    \n",
    "    \n",
    "count_list = []\n",
    "count = 0\n",
    "splitted_refseqs_list = []\n",
    "for item in splitted_short_orthologs_refseqs_sorted:\n",
    "    for key in list(item.keys()):\n",
    "        \n",
    "        for jey in list(item[key].keys()):\n",
    "            count+=1\n",
    "            splitted_refseqs_list.append(jey)\n",
    "    count_list.append(count)\n",
    "    count = 0\n",
    "\n",
    "print('Count in splitted:', len(splitted_refseqs_list))\n",
    "\n",
    "\n",
    "print('Number of sub-parts of short_orthologs_refseqs_sorted to be examined:', len(splitted_short_orthologs_refseqs_sorted))\n",
    "# print('Counts of refseqs in subparts:', count_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Selection - one protein seq per gene id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in splitted_short_orthologs_refseqs_sorted:\n",
    "    \n",
    "    \n",
    "    refseqs_string = '' \n",
    "    refseqs_list = []\n",
    "    \n",
    "    \n",
    "    for key in list(chunk.keys()):\n",
    "        for jey in list(chunk[key].keys()): \n",
    "            refseqs_string = refseqs_string + '&id=' + jey\n",
    "            refseqs_list.append(jey)\n",
    "                    \n",
    "    \n",
    "    urls = requests.get(\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=protein{}&api_key=aabfba1a0deb347c0ffdd37c6e46908c6a09&rettype=gp\".format(refseqs_string), auth=('user', 'pass'), timeout=(3.05, 27))\n",
    "    genpept_files = urls.text.split('//')\n",
    "    if '\\n\\n' in genpept_files: genpept_files.remove('\\n\\n')\n",
    "\n",
    "    # print('Number of downloaded files is the same as number of RefSeq numbers:', len(genpept_files) == len(refseqs_list))\n",
    "    # print(len(genpept_files), len(refseqs_list))\n",
    "    \n",
    "    count = -1\n",
    "    for geneid, refseqs_of_geneid in chunk.items(): \n",
    "        refseq_select = None\n",
    "        the_longest_seq = None\n",
    "        seq_len = 0\n",
    "\n",
    "        refseqs = list(refseqs_of_geneid.keys())\n",
    "      \n",
    "        # if there is more than one RefSeq sequence for gene id\n",
    "        if len(refseqs) > 1 and count < len(genpept_files):\n",
    "            for refseq in refseqs:\n",
    "                count += 1\n",
    "                genpept_file = genpept_files[count]\n",
    "                if refseq not in genpept_file: print('Error: File does not correspond to RefSeq number.')\n",
    "\n",
    "                # if the reference sequence is RefSeq Select, save it\n",
    "                if 'RefSeq Select' in genpept_file:    \n",
    "                    refseq_select = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'RefSeq_Select'}\n",
    "\n",
    "\n",
    "                # save the longest reference sequence \n",
    "                if len(refseqs_of_geneid[refseq]['protein_sequence']) > seq_len: \n",
    "                    seq_len = len(refseqs_of_geneid[refseq]['protein_sequence'])\n",
    "                    the_longest_seq = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'longest_seq'}\n",
    "\n",
    "\n",
    "            if refseq_select: \n",
    "                short_selected_orthologs_list.append(refseq_select)\n",
    "\n",
    "            elif the_longest_seq: \n",
    "                short_selected_orthologs_list.append(the_longest_seq)  \n",
    "            \n",
    "\n",
    "        else: # there is only one RefSeq\n",
    "            count += 1\n",
    "            refseq = list(refseqs_of_geneid.keys())[0]\n",
    "            only_one_seq = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'only_one_seq'}\n",
    "            short_selected_orthologs_list.append(only_one_seq) \n",
    "\n",
    "\n",
    "\n",
    "df_short_selected_orthologs_list = pd.DataFrame.from_dict(short_selected_orthologs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results: Short-living organisms; table of selected reference sequences; one per gene id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_short_selected_orthologs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4 LONG-living; Select reference sequences \n",
    "**Description of script:** It chooses which protein sequence will be used as a reference sequence.\n",
    "\n",
    "Sequence is chosen as a reference if there are keywords 'RefSeq Select' in GenPept file of the protein - script asks NCBI API for GenPept file and check it. Else the longest sequence from all protein sequences of that gene is chosen.\n",
    "\n",
    "seq_selection: \n",
    "  1. 'only_one_seq'; there was only one reference sequence in NCBI dtb\n",
    "  2. 'RefSeq_Select'; RefSeq Select in keywords of GenPept file\n",
    "  3. 'longest_seq'; the longest protein sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_selected_orthologs_list = [] \n",
    "# = list made of the 'orthologs_list' but containing only one seq per gene id\n",
    "# + information if it was chosen with RefSeq Select keyword or it is the longest sequence\n",
    "# [{human_gene_name: X, gene id: X, gene name: X, organism name; X, accession number: X, protein sequence: X, seq_selection: X}, {...}]\n",
    "\n",
    "\n",
    "# testing dictionary \n",
    "# all_orthologs_refseqs_sorted = {'gene_id1': {'NP_001104745': {'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}, 'XP_023505037.1': {'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}}, 'gene_id2': {'XP_023505041.1' :{'protein_sequence':'X', 'human_gene_name': 'X', 'gene_name': 'X', 'organism': 'X'}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(data, SIZE=10000):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        yield {k:data[k] for k in islice(it, SIZE)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Parse dictionary long_orthologs_refseqs_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all refseqs from dictionary long_orthologs_refseqs_sorted\n",
    "\n",
    "all_refseqs_list = [] \n",
    "gene_ids_list = []\n",
    "\n",
    "for key in list(long_orthologs_refseqs_sorted.keys()):\n",
    "    gene_ids_list.append(key)\n",
    "    for jey in list(long_orthologs_refseqs_sorted[key].keys()): \n",
    "        all_refseqs_list.append(jey)\n",
    "        \n",
    "print('Count of all gene ids:', len(gene_ids_list))\n",
    "print('Count of all refseqs:', len(all_refseqs_list), '\\n')\n",
    "\n",
    "\n",
    "\n",
    "# split the dictionary by 50 \n",
    "splitted_long_orthologs_refseqs_sorted = []\n",
    "\n",
    "\n",
    "for item in chunks({i:long_orthologs_refseqs_sorted[i] for i in long_orthologs_refseqs_sorted}, 10):\n",
    "    splitted_long_orthologs_refseqs_sorted.append(item)\n",
    "    \n",
    "    \n",
    "count_list = []\n",
    "count = 0\n",
    "splitted_refseqs_list = []\n",
    "for item in splitted_long_orthologs_refseqs_sorted:\n",
    "    for key in list(item.keys()):\n",
    "        \n",
    "        for jey in list(item[key].keys()):\n",
    "            count+=1\n",
    "            splitted_refseqs_list.append(jey)\n",
    "    count_list.append(count)\n",
    "    count = 0\n",
    "\n",
    "print('Count in splitted:', len(splitted_refseqs_list))\n",
    "\n",
    "\n",
    "print('Number of sub-parts of long_orthologs_refseqs_sorted to be examined:', len(splitted_long_orthologs_refseqs_sorted))\n",
    "# print('Counts of refseqs in subparts:', count_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: Selection - one protein seq per gene id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunk in splitted_long_orthologs_refseqs_sorted:\n",
    "    \n",
    "    refseqs_string = '' \n",
    "    refseqs_list = []\n",
    "    \n",
    "    \n",
    "    for key in list(chunk.keys()):\n",
    "        for jey in list(chunk[key].keys()): \n",
    "            refseqs_string = refseqs_string + '&id=' + jey\n",
    "            refseqs_list.append(jey)\n",
    "                    \n",
    "    \n",
    "    urls = requests.get(\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=protein{}&api_key=aabfba1a0deb347c0ffdd37c6e46908c6a09&rettype=gp\".format(refseqs_string), auth=('user', 'pass'), timeout=(10, 27))\n",
    "    genpept_files = urls.text.split('//')\n",
    "    if '\\n\\n' in genpept_files: genpept_files.remove('\\n\\n')\n",
    "    print(genpept_files)\n",
    "\n",
    "    # print('Number of downloaded files is the same as number of RefSeq numbers:', len(genpept_files) == len(refseqs_list))\n",
    "    # print(len(genpept_files), len(refseqs_list))\n",
    "\n",
    "    \n",
    "    count = -1\n",
    "    for geneid, refseqs_of_geneid in chunk.items(): \n",
    "        refseq_select = None\n",
    "        the_longest_seq = None\n",
    "        seq_len = 0\n",
    "\n",
    "        refseqs = list(refseqs_of_geneid.keys())\n",
    "      \n",
    "        # if there is more than one RefSeq sequence for gene id\n",
    "        if len(refseqs) > 1 and count < len(genpept_files):\n",
    "            for refseq in refseqs:\n",
    "                count += 1\n",
    "                print(refseq)\n",
    "                print(count)\n",
    "                genpept_file = genpept_files[count]\n",
    "                print(genpept_file)\n",
    "                if refseq not in genpept_file: print('Error: File does not correspond to RefSeq number.')\n",
    "\n",
    "                # if the reference sequence is RefSeq Select, save it\n",
    "                if 'RefSeq Select' in genpept_file:    \n",
    "                    refseq_select = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'RefSeq_Select'}\n",
    "\n",
    "\n",
    "                # save the longest reference sequence \n",
    "                if len(refseqs_of_geneid[refseq]['protein_sequence']) > seq_len: \n",
    "                    seq_len = len(refseqs_of_geneid[refseq]['protein_sequence'])\n",
    "                    the_longest_seq = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'longest_seq'}\n",
    "\n",
    "\n",
    "            if refseq_select: \n",
    "                long_selected_orthologs_list.append(refseq_select)\n",
    "\n",
    "            elif the_longest_seq: \n",
    "                long_selected_orthologs_list.append(the_longest_seq)  \n",
    "            \n",
    "\n",
    "        else: # there is only one RefSeq\n",
    "            count += 1\n",
    "            refseq = list(refseqs_of_geneid.keys())[0]\n",
    "            only_one_seq = {'human_gene_name': refseqs_of_geneid[refseq]['human_gene_name'], 'gene_id': geneid, 'gene_name': refseqs_of_geneid[refseq]['gene_name'], 'organism': refseqs_of_geneid[refseq]['organism'], 'accession_number': refseq, 'protein_sequence': refseqs_of_geneid[refseq]['protein_sequence'], 'seq_selection':'only_one_seq'}\n",
    "            long_selected_orthologs_list.append(only_one_seq) \n",
    "\n",
    "\n",
    "\n",
    "df_long_selected_orthologs_list = pd.DataFrame.from_dict(long_selected_orthologs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results: Long-living organisms; table of selected reference sequences; one per gene id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_long_selected_orthologs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Divide files from NCBI Datasets into subparts (NCBI connection error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.listdir(r'{0}\\NCBI_Datasets_download'.format(main_path))\n",
    "folder.remove('.ipynb_checkpoints')\n",
    "name = 1\n",
    "counter = 0\n",
    "\n",
    "\n",
    "os.system('mkdir {0}\\\\NCBI_Datasets_download\\\\{1}'.format(str(win_path, name)))\n",
    "          \n",
    "for gene in folder:\n",
    "    if counter < 20:\n",
    "        os.system('move {0}\\\\NCBI_Datasets_download\\\\{1} {0}\\\\NCBI_Datasets_download\\\\{2}'.format(win_path, gene, str(name)))\n",
    "        counter += 1\n",
    "        \n",
    "    else:\n",
    "        name += 1\n",
    "        os.system('mkdir {0}\\\\NCBI_Datasets_download\\\\{1}'.format(str(win_path, name)))\n",
    "        counter = 0\n",
    "        os.system('move {0}\\\\NCBI_Datasets_download\\\\{1} {0}\\\\NCBI_Datasets_download\\\\{2}'.format(win_path, gene, str(name)))\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6 Create files for CAASTools Discovery analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script: Create config file with organisms and 0 (short-living) / 1 (long-living)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = open(r'{0}\\CAASTools_files\\config.txt'.format(main_path),\"w\")\n",
    "\n",
    "for organism in short_living_list: \n",
    "    config_file.write(organism.lower() + '\\t' + '0' + '\\n')\n",
    "for organism in long_living_list: \n",
    "    config_file.write(organism.lower() + '\\t' + '1' + '\\n')\n",
    "\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script: Create fasta file for clustal omega multiple sequence alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seq = long_selected_orthologs_list + short_selected_orthologs_list\n",
    "genes = df_genes_organisms.index.values.tolist()\n",
    "\n",
    "for gene in genes:\n",
    "    gene_file = open(r'{0}\\CAASTools_files\\fasta_files\\{1}.fasta'.format(main_path, gene),\"w\")\n",
    "\n",
    "    for item in all_seq:\n",
    "        if gene in item.values(): \n",
    "            gene_file.write('>' + str(item['organism']).replace(' ', '_').lower() + '\\n')\n",
    "            gene_file.write(str(item['protein_sequence']) + '\\n')\n",
    "\n",
    "    gene_file.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Script: MSAs by Clustal omega\n",
    "!!! It is needed to download the Clustal Omega program and save the folder \"clustal-omega-1.2.2-win64\" with the program \"clustalo.exe\" to main folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene in genes:\n",
    "    os.system('{0}\\\\clustal-omega-1.2.2-win64\\\\clustalo.exe -i {0}\\\\CAASTools_files\\\\fasta_files\\\\{1}.fasta --out {0}\\\\CAASTools_files\\\\MSA_results\\\\{1}.msa --outfmt clu --wrap=10000'.format(win_path, gene))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### stress_molecules.csv\n",
    "table of stress molecules (downloaded from Reactome - with Reactome IDs requested, and checked with HGNC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stress_molecules.to_csv(r'{0}\\stress_molecules\\stress_molecules.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### multiple_paths_check.csv\n",
    "table of gene symbols and Reactome IDs; i.e. some genes may be involved in multiple paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_paths_df.to_csv(r'{0}\\results\\gene_in_multiple_paths_check.csv'.format(main_path).format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### orthologs.csv \n",
    "table of orthologs and their atributes (i.e. FASTA file parsed into table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orthologs_list.to_csv(r'{0}\\NCBI_Datasets_download\\orthologs.csv'.format(main_path), sep=',', encoding='utf-8')      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### orthologs_count.csv\n",
    "table of gene ids and their protein sequence counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ortholog_count_list.to_csv(r'{0}\\results\\orthologs_count.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### genes_organisms_check.csv\n",
    "table of genes-organisms check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes_organisms.to_csv(r'{0}\\results\\genes_organisms_check.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anage_animaltraits_data_merge.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anage_animaltraits.to_csv(r'{0}\\results\\anage_animaltraits_data_merge.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organisms_lq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_organisms_lq.to_csv(r'{0}\\results\\organisms_lq.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### short_living_organisms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_living.to_csv(r'{0}\\results\\short_living_organisms.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### long_living_organisms.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long_living.to_csv(r'{0}\\results\\long_living_organisms.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### long_selected_orthologs.csv\n",
    "table of selected sequences one reference sequence per gene id (i.e. orthologous gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_long_selected_orthologs_list.to_csv(r'{0}\\results\\long_selected_orthologs.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### short_selected_orthologs.csv\n",
    "table of selected sequences one reference sequence per gene id (i.e. orthologous gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_short_selected_orthologs_list.to_csv(r'{0}\\results\\short_selected_orthologs.csv'.format(main_path), sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
